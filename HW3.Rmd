---
title: "Time Series HW 3"
author: |
  | Kenny Flagg and Paul Harmon
  | __who have not yet worked together and want the bonus!__
date: "September 16, 2016"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## HW 3

_You can alone or in pairs that may or may not be people you worked with before. You can discuss it with old partners but should try work as much as possible with new collaborators. 5% bonus if you find someone completely new to work with - that you did not work with on first two assignments._

_I mentioned de-seasonalizing of time series, where the seasonal variation is removed from the series to highlight variation at either higher or lower frequencies. There are a variety of techniques for doing this but the simplest is to just subtract the mean for each month from the observations. And the easiest way to find that is using `lm(y~month,data=...)`._

1) _For the Bozeman temperature data from HW 1 and 2, estimate a model with month only, subtract its fitted values from the responses (or just extract residuals). Plot the residuals vs the fractional `Year` variable and compare the plot of this result to the plot of the original time series._

    ```{r problem 1}
weather = read.csv("rawbozemandata.csv", header = TRUE)

weather$YEAR = substr(as.character(weather$DATE), 0,nchar(weather$DATE)-2)
weather$MONTH = as.factor(substr(as.character(weather$DATE),5,nchar(weather$DATE)))
weather$year = (floor(weather$DATE/100))
weather$Month<-round((weather$DATE/100-weather$year)*100,1)
weather$Yearfrac<-weather$year+(weather$Month-1)/12 #makes it an integer variable
#fit the linear model
lm.weather = lm(MMXT ~ MONTH, data = weather)
#lm.weather$residuals
plot(weather$Yearfrac, lm.weather$residuals, pch = 20, col = "orange4",
     main = "Residuals vs. Year", xlab = "Year", ylab = "Residuals")
```


2) _In the de-seasonalized Bozeman temperature data set, re-assess evidence for the linear trend. Compare the result (test statistic, degrees of freedom and size of p-value) of just fitting a linear time trend in these de-seasonalized responses to the result from our original model with a linear year component and a month adjustment (not the quadratic trend model)._

    ```{r problem 2}
lm.seasoned <- lm(MMXT ~ Yearfrac + MONTH, data = weather)
lm.deseasoned <- lm(lm.weather$residuals ~ Yearfrac, data = weather)
summary(lm.seasoned)
summary(lm.deseasoned)
```

    After de-seasonalization, there is strong evidence of a linear trend in MMXT through time ($t_{1372}=14.00$, p-value $<0.0001$). This is very similar to the result when when month is included as a factor, where the estimated year term has $t_{1361}=13.94$ with p-value $<0.0001$. It seems like the degrees of freedom for the de-seasonalized model is wrong because it doesn't account for estimating the monthly means.


3) _I briefly discussed the HADCRUT data set in class. We will consider the HADCRUT4 series of temperature anomalies for the Nothern Hemisphere. The fully up to date data set is available at: `http://www.metoffice.gov.uk/hadobs/hadcrut4/data/current/time_series/HadCRUT.4.4.0.0.monthly_nh.txt`_

    _Download the ensemble median monthly northern hemisphere temperature data. We will use the entire time series that is currently available (January 1850 to July 2016). You might want to read `http://www.metoffice.gov.uk/hadobs/hadcrut4/data/current/series_format.html` for more information on the columns in the data set._

     _Because the time series is complete over the time frame under consideration, you can use `ts()` to create a time variable instead of messing around with their `Year/Month` variable._

    _Make a plot versus time of the ensemble medians and use that as your response variable in the following questions. Discuss trend, seasonality, outliers, and variability._

    ```{r problem 3}
hadcrut <- read.table('HadCRUT.4.4.0.0.monthly_nh.txt',
                      col.names = c('Date', 'median.temp.anom',
                                    'bias.l95', 'bias.u95',
                                    'meas.l95', 'meas.u95',
                                    'coverage.l95', 'coverage.u95',
                                    'error.l95', 'error.u95',
                                    'l95', 'u95'))
hadcrut.ts <- ts(hadcrut$median.temp.anom, start = 1850, frequency = 12)
```

4) _Our main focus with these data will be on estimating the long-term trend, starting with polynomial trend models. But first, check for seasonality in a model that accounts for a linear time trend. Use our previous fractional year for the trend. Report an `effects` plot and a test for the month model component._

    _Note: when you use `time()` to generate the `Year` variable from a time series object it retains some time series object information that can cause conflicts later on. Create a new variable in your data.frame that uses something like `as.vector(time(tsdataname))`._

    ```{r problem 4, message = FALSE}
hadcrut$yearfrac <- time(hadcrut.ts)
had.lm1 <- lm(median.temp.anom ~ yearfrac, data = hadcrut)
summary(had.lm1)

require(effects)
plot(allEffects(had.lm1))
```

5) _Check the residuals versus fitted values for any evidence of nonlinearity in the residuals vs fitted that was missed by the model with a linear trend and month component. Also note any potential issues with the constant variance assumption._

6) _You can add higher order polynomial terms to models using `x1+I(x1^2)+I(x1^3)`... or using the `poly` function, such as `poly(x1,3,raw=T)` for a cubic polynomial that includes the linear and quadratic components (we want this!). The `raw=T` keeps the variables in their raw or input format. Estimate the same model but now using polynomial trends that steps up from linear (poly(time,1,raw=T)) and stop when you get a failure to estimate a part of the model. Briefly discuss what happened._

7) _If we center or, even better, make the polynomial functions orthogonal to one another, we can avoid the issue in the previous question. Use `poly(x1,?,raw=F)` and step up the polynomial order for time until the p-value for the last coefficient (use `summary()`) is "large", reporting the single test result for each step in the building process. Then drop back one order and re-fit the model. Report the `effects` plot of the resulting model and describe the estimated trend. Note: aside from access to orthogonal polynomials the `poly` function interfaces with `Anova` and the `effects` package really nicely._

8) _Check the diagnostic plots from your final model. Does anything improve from the first version. Also plot the residuals vs time and compare that plot to residuals vs fitted._


9) _Run the following code so I can see what version of R you are now using:_

### Documenting R version 

```{r}
sessionInfo()$R.version$nickname
getRversion()
```
